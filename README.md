# VQA using MLX

This repository contains the code for a simple Visual Question Answering (VQA) system using the mlx library and the Qwen2 Model.

## Table of Contents
- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Introduction
Visual Question Answering (VQA) is a task that involves answering questions based on the content of an image. This repository demonstrates a basic implementation using the mlx library along with the Qwen2 model.

## Installation
To get started with this project, clone the repository and install the necessary dependencies.

```bash
git clone https://github.com/shrish23/VQA-using-MLX.git
cd VQA-using-MLX
pip install -r requirements.txt
```

## Usage
The notebook uses opencv to capture the frame from the device and have a more realistic VQA.//
Prepare your dataset and place it in the data/ directory.
Run the Jupyter notebooks provided in the repository to train and test the VQA model.
